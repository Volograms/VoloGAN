# VoloGAN

Paper: 

## Abstract: 

Training a machine learning model requires representative training data of the target application. In
some cases, data is either not available in the required amount or only similar data from another data
domain is available. Data can be synthetically generated by translating data from one domain into
another domain using adversarial learning approaches. The CycleGAN framework is a generative
adversarial network that is used for unpaired data-to-data translation tasks. Among other challenges
CycleGANs have a high number of hyperparameters and different architectural complexities between
the discriminator and the generator. Furthermore, the learning objective is qualitatively more complex
for the generator than for the discriminator. In addition, especially for high resolution multi-channel
images, models become complex and require many resources to train.

In this study, there are two different domains of RGBD images with the dimensions 512x512x4.
Images from the first domain are generated using photogrammetry and the images from the second
domain are generated from a mobile phone using a LiDAR scanner. The objective of this work is to
translate RGBD images generated using photogrammetry into images that could be generated by the
mobile phoneâ€™s LiDAR scanner.

We investigated different model architectures for our generator and for our discriminator. Our
Generator is based on the U-Net architecture and our discriminator is based on the SIV-GAN. We
investigated different activation functions and initializer. In addition, frequently used layers such as
normalization, dropout, padding and up and downsampling had been critically reviewed and adapted.
Furthermore, the training objective of the CycleGAN is improved by considering the structural
similarity, a channel wise loss to avoid channel pollution and a switching of the pixel loss from MAE
to MSE. Finally, different optimizers are applied to train the generator and the discriminator, where
the learning rate is scheduled containing a warm-up phase and a decay phase.
It is demonstrated that with carefully engineered model architectures, an optimized usage of the
training hardware, extensive hyperparameter tuning and custom enhancements of TensorFlow, Cycle-
GANs can be used to apply adversarial domain adaptation of synthetic 3D data to train a volumetric
video generator model having only few training samples.

## Architecture: 
<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/vologan.png" width="800" />

### Generator
<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/generator_model.png" width="800" />

### Discriminator
<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/critic_model.png" width="500" />

## Results:

### PCA - Principal Component Analysis

**Before Training**

<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/pca_before.PNG" width="200" />

**After Training**

<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/pca_after.PNG" width="200" />

### 3D Point Clouds
**Input RGBD**

<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/3d_pointcloud_input.png" width="500" />

**Generated RGBD**

<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/3d_pointcloud_generated.png" width="500" />

### Generated RGBD
<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/multiple_rgb.png" width="500" />
<img src="https://github.com/sascha-kirch/VoloGAN/blob/master/imgs/multiple_depth.png" width="500" />


